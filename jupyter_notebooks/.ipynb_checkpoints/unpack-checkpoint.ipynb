{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unpack\n",
    "\n",
    "`unpack.ipynb` is a utility used to process the NYT Annotated Corpus' XML files to extract particular tags of information, and append it to a DataFrame. A file is generated from this script that will be used for further processing.  \n",
    "\n",
    "  \n",
    "  The files produced from the script are used in later ones ( `processing.ipynb` and `analysis.ipynb` )\n",
    "  \n",
    "  Running time for the script can be lengthy depending on the values entered for year, month, and date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "The XML library is used to parse and traverse the .xml files provided in the corpus.  \n",
    "The glob library is used to be able to find files using regular expressions to loop through multiple files.  \n",
    "The pandas library is used to hold all of the information that is extracted from the corpus.  \n",
    "The pickle library is used to serialize the DataFrame object into a file, to be loaded and used by another script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as Et\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a New DataFrame\n",
    "This creates a new, empty DataFrame to read in information from the NYT Annotated Corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['DOCID', 'Date', 'Month', 'Year', 'Name', 'Text']\n",
    "data = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Dates of Desired Files\n",
    "The variables used below are able to be modified in order to determine what month, day, and year to extract and process files from.  \n",
    "All values are in numerical format. Single digit values are expressed as `01`, `02`, `...`, `09`.  \n",
    "If you wish to use all of a specific type of value, use the `*` instead of a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year = \"2005\"\n",
    "month = \"*\"\n",
    "day = \"*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin Processing Files from NYT Annotated Corpus\n",
    "Using the values for year, month, day, the glob library is able to get the file names that match a particular path, represented as a regular expression.  \n",
    "  \n",
    "The data being extracted are:\n",
    "- docid\n",
    "- date\n",
    "- month\n",
    "- year\n",
    "- identified name\n",
    "\n",
    "  \n",
    "Values are stored in a DataFrame called `data`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open each xml file in the specified folder, open it and print out the names of mentioned people\n",
    "for file in glob.glob(\"../data/NYT Corpus/nyt_corpus/data/\"+year+\"/\"+month+\"/\"+day+\"/*.xml\"):\n",
    "    # parse the xml file into an element tree to extract data\n",
    "    tree = Et.parse(file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # get document id information (not sure if I need this yet, seems like it could be helpful)\n",
    "    docid = root.find('.//doc-id[@id-string]').attrib['id-string']\n",
    "        \n",
    "    # get publication date information\n",
    "    date = root.find(\".//meta[@name='publication_day_of_month']\").attrib['content']\n",
    "    month = root.find(\".//meta[@name='publication_month']\").attrib['content']\n",
    "    year = root.find(\".//meta[@name='publication_year']\").attrib['content']\n",
    "    \n",
    "    # get article text information\n",
    "    # some articles seem to lack text - this is caught and handled in the if/else\n",
    "    article = root.find(\".//block[@class='full_text']/p\")\n",
    "    if article is not None:\n",
    "        text = (article.text).lower()\n",
    "    else:\n",
    "        text = None\n",
    "        \n",
    "    # for each person mentioned, create a new row of data for them in the dataframe    \n",
    "    for c in root.iter('person'):\n",
    "        name = str(c.text).upper()\n",
    "        data = data.append([{'DOCID': docid, 'Date': date, 'Month': month, 'Year': year, 'Name': name, 'Text': text}])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the DataFrame\n",
    "For readability, the DataFrame is sorted below by Month and then by Date. The minimum preferred granularity for processing files is by year. Any larger than that and the script would take too long to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.sort_values(ascending=[True, True], by=['Month', 'Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify that the DataFrame is Sorted at the Beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify that the DataFrame is Sorted at the End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Out the Resulting DataFrame to a File\n",
    "The DataFrame is serialized below using the pickle library. The filename is taken from the `year` variable. Pickle files from this script carry the `.p` extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(data, open(\"nyt-\" + year + \".p\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
